{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cdf6c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pyproj\n",
    "import netCDF4\n",
    "import datetime\n",
    "import pyresample\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea53ea",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0544303d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGE_TASK_ID = 1\n",
    "#\n",
    "date_min = \"20200901\"\n",
    "date_max = \"20230602\"\n",
    "#\n",
    "hours_AMSR2 = \"H03\"\n",
    "#\n",
    "paths = {}\n",
    "paths[\"AMSR2\"] = \"/lustre/storeB/project/nwp/H2O/wp3/satellite_data/AMSR-2/\"\n",
    "paths[\"surfex\"] = \"/lustre/storeB/users/josteinbl/sfx_data/LDAS_NOR/archive/\"\n",
    "paths[\"surfex_grid\"] = \"/lustre/storeB/users/josteinbl/sfx_data/LDAS_NOR/climate/\"\n",
    "paths[\"output\"] = \"/lustre/storeB/project/nwp/H2O/wp3/Deep_learning_predictions/Training_data/\"\n",
    "#\n",
    "surfex_inputgrid = paths[\"surfex_grid\"] + \"PGD.nc\"\n",
    "#\n",
    "target_variables = [\"tb6_h\", \"tb6_v\", \"tb7_h\", \"tb7_v\", \"tb10_h\", \"tb10_v\", \"tb18_h\", \"tb18_v\", \"tb23_h\", \"tb23_v\", \"tb36_h\", \"tb36_v\"]\n",
    "#\n",
    "surfex_PGD_variables = [\"ZS\", \"COVER004\", \"COVER006\"]\n",
    "surfex_prognostic_variables = [\"FRAC_WATER\", \"FRAC_NATURE\", \"FRAC_SEA\"]\n",
    "surfex_surface_and_integrated_variables = [\"Q2M_ISBA\", \"T2M_ISBA\", \"TS_ISBA\", \"DSN_T_ISBA\", \"LAI_ga\", \"PSN_ISBA\", \"PSNG_ISBA\", \"PSNV_ISBA\"]\n",
    "predictor_variables = surfex_prognostic_variables + surfex_surface_and_integrated_variables\n",
    "#\n",
    "n_soil_layers = 12\n",
    "surfex_soil_variables = [\"TG\", \"WSN_VEG\", \"WG\", \"WGI\", \"RSN_VEG\", \"SNOWTEMP\", \"SNOWLIQ\", \"HSN_VEG\"] \n",
    "#\n",
    "for var in surfex_soil_variables:\n",
    "    for layer in range(1, n_soil_layers + 1):\n",
    "        predictor_variables.append(var + str(layer) + \"_ga\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259457c",
   "metadata": {},
   "source": [
    "# Get surfex coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ff83b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class get_surfex_coordinates():\n",
    "    def __init__(self, surfex_inputgrid, surfex_PGD_variables):\n",
    "        self.inputgrid = surfex_inputgrid\n",
    "        self.surfex_PGD_variables = surfex_PGD_variables\n",
    "    #\n",
    "    def sfx2areadef(self, lat0, lon0, latori, lonori, xx, yy):\n",
    "        proj2 = \"+proj=lcc +lat_1=%.2f +lat_2=%.2f +lat_0=%.2f +lon_0=%.2f +units=m +ellps=WGS84 +no_defs\" % (lat0,lat0,lat0,lon0)\n",
    "        p2 = pyproj.Proj(proj2,preserve_units = False)\n",
    "        origo = p2(lonori.data,latori.data)\n",
    "        extent = origo + (origo[0] + xx[-1,-1], origo[1] + yy[-1,-1])\n",
    "        area_def = pyresample.geometry.AreaDefinition(\"id2\",\"hei2\",\"lcc\",proj2,xx.shape[1],yy.shape[0],extent)\n",
    "        return(area_def)\n",
    "    #\n",
    "    def getSFXgrid(self):\n",
    "        nc = netCDF4.Dataset(self.inputgrid, \"r\")\n",
    "        lon0 = nc[\"LON0\"][0]\n",
    "        lat0 = nc[\"LAT0\"][0]\n",
    "        lonc = nc[\"LONORI\"][0]\n",
    "        latc = nc[\"LATORI\"][0]\n",
    "        #\n",
    "        dx = nc[\"DX\"][:]\n",
    "        dy = nc[\"DY\"][:]\n",
    "        #\n",
    "        xx = nc[\"XX\"][:]\n",
    "        yy = nc[\"YY\"][:]\n",
    "        nc.close()\n",
    "        #\n",
    "        x = xx[0,:]\n",
    "        y = yy[:,0]\n",
    "        #\n",
    "        areadef = self.sfx2areadef(lat0, lon0, latc, lonc, xx, yy)\n",
    "        return(areadef, x, y)\n",
    "    #\n",
    "    def load_PGD_variables(self):\n",
    "        Surfex_PGD = {}\n",
    "        nc = netCDF4.Dataset(self.inputgrid, \"r\")\n",
    "        for var in self.surfex_PGD_variables:\n",
    "            Surfex_PGD[var] = nc.variables[var][:,:]\n",
    "        nc.close()\n",
    "        return(Surfex_PGD)\n",
    "    #\n",
    "    def __call__(self):\n",
    "        areadef, x, y = self.getSFXgrid()\n",
    "        lon, lat = areadef.get_lonlats()\n",
    "        Surfex_PGD = self.load_PGD_variables()\n",
    "        #\n",
    "        Surfex_coord = {}\n",
    "        Surfex_coord[\"lon\"] = lon\n",
    "        Surfex_coord[\"lat\"] = lat\n",
    "        Surfex_coord[\"x\"] = x\n",
    "        Surfex_coord[\"y\"] = y\n",
    "        #\n",
    "        return(Surfex_coord, Surfex_PGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa806e",
   "metadata": {},
   "source": [
    "# List dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a246530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list_dates(date_min, date_max):\n",
    "    current_date = datetime.datetime.strptime(date_min, \"%Y%m%d\")\n",
    "    end_date = datetime.datetime.strptime(date_max, \"%Y%m%d\")\n",
    "    list_dates = []\n",
    "    while current_date <= end_date:\n",
    "        date_str = current_date.strftime(\"%Y%m%d\")\n",
    "        list_dates.append(date_str)\n",
    "        current_date = current_date + datetime.timedelta(days = 1)\n",
    "    return(list_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c79f2e",
   "metadata": {},
   "source": [
    "# Read AMSR2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac55305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_AMSR2_data(date_task, paths, target_variables):\n",
    "    AMSR2_data = {}\n",
    "    #\n",
    "    file_AMSR2 = paths[\"AMSR2\"] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + date_task[6:8] + \"/AMSR2_SOR_TEST_\" + date_task + \".nc\"\n",
    "    nc = netCDF4.Dataset(file_AMSR2, \"r\")\n",
    "    dim_1D = nc.dimensions[\"N_DIM\"].size\n",
    "    dim_2D = (int(np.sqrt(dim_1D)), int(np.sqrt(dim_1D)))\n",
    "    #\n",
    "    for var in target_variables:\n",
    "        var_data = np.flipud(np.reshape(nc.variables[var][:], dim_2D, order = \"F\"))\n",
    "        var_data[var_data < 0] = np.nan\n",
    "        AMSR2_data[var] = np.copy(var_data)\n",
    "    #\n",
    "    nc.close()\n",
    "    return(AMSR2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be751534",
   "metadata": {},
   "source": [
    "# Read SURFEX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41ada193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_surfex_data(date_task, paths, predictor_variables):\n",
    "    Surfex_data = {}\n",
    "    filename_constants = paths[\"surfex\"] + \"2023/01/01/00/SURFOUT.20230101_03h00.nc\"\n",
    "    previous_hours = \"{:02d}\".format(int(date_task[9:11]) - 3)\n",
    "    path_task = paths[\"surfex\"] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + date_task[6:8] + \"/\" +  previous_hours + \"/\"\n",
    "    print(\"SURFOUT.\" + date_task[0:8] + \"_\" + date_task[9:11] + \"h00.nc\")\n",
    "    nc = netCDF4.Dataset(path_task + \"SURFOUT.\" + date_task[0:8] + \"_\" + date_task[9:11] + \"h00.nc\", \"r\")\n",
    "    #\n",
    "    Surfex_coord = {}\n",
    "    for var in [\"XX\", \"YY\"]:\n",
    "        if var in nc.variables:\n",
    "            var_data = nc.variables[var][:,:]\n",
    "            if var == \"XX\":\n",
    "                Surfex_coord[\"x\"] = var_data[0,:]\n",
    "            elif var == \"YY\":\n",
    "                Surfex_coord[\"y\"] = var_data[:,0]\n",
    "        else:\n",
    "            nc_constants = netCDF4.Dataset(filename_constants)\n",
    "            var_data = nc_constants.variables[var][:,:]\n",
    "            if var == \"XX\":\n",
    "                Surfex_coord[\"x\"] = var_data[0,:]\n",
    "            elif var == \"YY\":\n",
    "                Surfex_coord[\"y\"] = var_data[:,0]\n",
    "            nc_constants.close()\n",
    "    #\n",
    "    for var in [\"PATCHP1\", \"PATCHP2\"]:\n",
    "        if var in nc.variables:\n",
    "            var_data = nc.variables[var][:,:]\n",
    "            var_data[var_data.mask == True] = 0\n",
    "            Surfex_data[var] = np.expand_dims(var_data, axis = 0)\n",
    "        else:\n",
    "            nc_constants = netCDF4.Dataset(filename_constants)\n",
    "            var_data = nc_constants.variables[var][:,:]\n",
    "            var_data[var_data.mask == True] = 0\n",
    "            Surfex_data[var] = np.expand_dims(var_data, axis = 0)\n",
    "            nc_constants.close()\n",
    "    #\n",
    "    for var in predictor_variables:\n",
    "        try:\n",
    "            if (var in nc.variables) or (var.replace(\"_ga\", \"P1\") in nc.variables):\n",
    "                if \"_ga\" in var:\n",
    "                    var_data_P1 = nc.variables[var.replace(\"_ga\", \"P1\")][:,:]\n",
    "                    var_data_P2 = nc.variables[var.replace(\"_ga\", \"P2\")][:,:]\n",
    "                    var_data_P1 = np.expand_dims(var_data_P1, axis = 0)\n",
    "                    var_data_P2 = np.expand_dims(var_data_P2, axis = 0)\n",
    "                    Surfex_data[var] = np.nansum([Surfex_data[\"PATCHP1\"] * var_data_P1, Surfex_data[\"PATCHP2\"] * var_data_P2], axis = 0)\n",
    "                    Surfex_data[var][var_data_P1.mask == True] = var_data_P2[var_data_P1.mask == True]\n",
    "                    Surfex_data[var][var_data_P2.mask == True] = var_data_P1[var_data_P2.mask == True]\n",
    "                    Surfex_data[var][np.logical_and(var_data_P1.mask == True, var_data_P2.mask == True)] = np.nan\n",
    "                else:\n",
    "                    Surfex_data[var] = nc.variables[var][:,:]\n",
    "            else:\n",
    "                #print(\"prognostic variable: \", var)\n",
    "                ncp = netCDF4.Dataset(path_task + \"SURFOUT.nc\")\n",
    "                if \"_ga\" in var:\n",
    "                    var_data_P1 = ncp.variables[var.replace(\"_ga\", \"P1\")][:,:]\n",
    "                    var_data_P2 = ncp.variables[var.replace(\"_ga\", \"P2\")][:,:]\n",
    "                    var_data_P1 = np.expand_dims(var_data_P1, axis = 0)\n",
    "                    var_data_P2 = np.expand_dims(var_data_P2, axis = 0)\n",
    "                    Surfex_data[var] = np.nansum([Surfex_data[\"PATCHP1\"] * var_data_P1, Surfex_data[\"PATCHP2\"] * var_data_P2], axis = 0)\n",
    "                    Surfex_data[var][var_data_P1.mask == True] = var_data_P2[var_data_P1.mask == True]\n",
    "                    Surfex_data[var][var_data_P2.mask == True] = var_data_P1[var_data_P2.mask == True]\n",
    "                    Surfex_data[var][np.logical_and(var_data_P1.mask == True, var_data_P2.mask == True)] = np.nan\n",
    "                else:\n",
    "                    Surfex_data[var] = ncp.variables[var][:,:]\n",
    "                ncp.close()\n",
    "        except:\n",
    "            print(\"Variable not found: \" + var)\n",
    "            if (var == \"SNOWTEMP9_ga\") or (var == \"SNOWLIQ9_ga\"):\n",
    "                pass\n",
    "            else:\n",
    "                sys.exit()\n",
    "    #\n",
    "    nc.close()\n",
    "    return(Surfex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f0b91a9-9048-4326-8242-b879a8de8b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_WSN_T_ISBA(Surfex_data, n_soil_layers):\n",
    "    WSN_T_ISBA = np.zeros(np.shape(Surfex_data[\"WSN_VEG1_ga\"]))\n",
    "    for layer in range(0, n_soil_layers):\n",
    "        WSN_T_ISBA = WSN_T_ISBA + Surfex_data[\"WSN_VEG\" + str(layer + 1) + \"_ga\"]\n",
    "    return(WSN_T_ISBA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ada498",
   "metadata": {},
   "source": [
    "# Write netCDF output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f8e16353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_netcdf(date_task, paths, Surfex_coord, Surfex_PGD, Targets, Surfex_data):\n",
    "    path_output = paths[\"output\"] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\"\n",
    "    if os.path.exists(path_output) == False:\n",
    "        os.system(\"mkdir -p \" + path_output)    \n",
    "    output_filename = path_output + \"Dataset_\" + date_task + \".nc\"\n",
    "    if os.path.isfile(output_filename):\n",
    "        os.system(\"rm \" + output_filename)\n",
    "    output_netcdf = netCDF4.Dataset(output_filename, 'w', format = 'NETCDF4')\n",
    "    #\n",
    "    x = output_netcdf.createDimension(\"x\", len(Surfex_coord[\"x\"]))\n",
    "    y = output_netcdf.createDimension(\"y\", len(Surfex_coord[\"y\"]))\n",
    "    #\n",
    "    Outputs = vars()\n",
    "    #\n",
    "    for var in Targets:\n",
    "        Outputs[var] = output_netcdf.createVariable(var, \"d\", (\"y\", \"x\"))\n",
    "        Outputs[var][:,:] = Targets[var]\n",
    "    for var in Surfex_PGD:\n",
    "        Outputs[var] = output_netcdf.createVariable(var, \"d\", (\"y\", \"x\"))\n",
    "        Outputs[var][:,:] = Surfex_PGD[var]        \n",
    "    for var in Surfex_data:\n",
    "        Outputs[var] = output_netcdf.createVariable(var, \"d\", (\"y\", \"x\"))\n",
    "        Outputs[var][:,:] = np.squeeze(Surfex_data[var])\n",
    "    #\n",
    "    output_netcdf.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d75b18",
   "metadata": {},
   "source": [
    "# Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f7b706b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SURFOUT.20230108_03h00.nc\n"
     ]
    }
   ],
   "source": [
    "list_dates = make_list_dates(date_min, date_max)\n",
    "date_task = list_dates[SGE_TASK_ID - 1] + hours_AMSR2\n",
    "#\n",
    "Surfex_coord, Surfex_PGD = get_surfex_coordinates(surfex_inputgrid, surfex_PGD_variables)()\n",
    "Targets = read_AMSR2_data(date_task, paths, target_variables)\n",
    "Surfex_data = read_surfex_data(date_task, paths, predictor_variables)\n",
    "Surfex_data[\"WSN_T_ISBA\"] = calculate_WSN_T_ISBA(Surfex_data, n_soil_layers)\n",
    "Surfex_data[\"FRAC_LAND_AND_SEA_WATER\"] = Surfex_data[\"FRAC_WATER\"] + Surfex_data[\"FRAC_SEA\"] \n",
    "Surfex_data[\"SNOW_GRADIENT\"] = (Surfex_data[\"SNOWTEMP12_ga\"] - Surfex_data[\"SNOWTEMP1_ga\"]) / Surfex_data[\"DSN_T_ISBA\"]\n",
    "Surfex_data[\"SNOW_GRADIENT\"][Surfex_data[\"SNOW_GRADIENT\"] > 50] = 50\n",
    "Surfex_data[\"SNOW_GRADIENT\"][Surfex_data[\"SNOW_GRADIENT\"] < -50] = -50\n",
    "#\n",
    "write_netcdf(date_task, paths, Surfex_coord, Surfex_PGD, Targets, Surfex_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:development-11-2023]",
   "language": "python",
   "name": "conda-env-development-11-2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
