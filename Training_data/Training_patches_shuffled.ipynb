{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1bbbd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "import netCDF4\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d30846",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7f25a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "paths[\"data\"] = \"/lustre/storeB/project/nwp/H2O/wp3/Deep_learning_predictions/Patches/Training_data/\"\n",
    "paths[\"output\"] = \"/lustre/storeB/project/nwp/H2O/wp3/Deep_learning_predictions/Patches/Training_patches/\"\n",
    "#\n",
    "date_min = \"20200901\"\n",
    "date_max = \"20220601\"\n",
    "#\n",
    "target_var_cleaning = \"tb18_v\"\n",
    "patch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071e77ea",
   "metadata": {},
   "source": [
    "# Create Patch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "592e53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_patch_file():\n",
    "    def __init__(self, date_min, date_max, paths):\n",
    "        self.date_min = date_min\n",
    "        self.date_max = date_max\n",
    "        self.paths = paths\n",
    "    #\n",
    "    def make_list_dates(self):\n",
    "        current_date = datetime.datetime.strptime(self.date_min, \"%Y%m%d\")\n",
    "        end_date = datetime.datetime.strptime(self.date_max, \"%Y%m%d\")\n",
    "        list_dates = []\n",
    "        while current_date <= end_date:\n",
    "            date_str = current_date.strftime(\"%Y%m%d\")\n",
    "            filename = self.paths[\"data\"] + date_str[0:4] + \"/\" + date_str[4:6] + \"/Dataset_\" + date_str +  \".nc\"\n",
    "            if os.path.isfile(filename) == True:\n",
    "                list_dates.append(date_str)\n",
    "            current_date = current_date + datetime.timedelta(days = 1)\n",
    "        return(list_dates)\n",
    "    #\n",
    "    def read_data(self, date_task):\n",
    "        Dataset = {}\n",
    "        filename = self.paths[\"data\"] + date_task[0:4] + \"/\" + date_task[4:6] + \"/\" + \"Dataset_\" + date_task + \".nc\"\n",
    "        nc = netCDF4.Dataset(filename, \"r\")\n",
    "        for var in nc.variables:\n",
    "            Dataset[var] = nc.variables[var][:,:]\n",
    "        nc.close()\n",
    "        return(Dataset)\n",
    "    #\n",
    "    def concatenate_patches(self):\n",
    "        list_dates = self.make_list_dates()\n",
    "        for di, date_task in enumerate(list_dates):\n",
    "            Dataset = self.read_data(date_task)\n",
    "            #\n",
    "            if di == 0:\n",
    "                Patches = Dataset.copy()\n",
    "            else:\n",
    "                for var in Dataset:\n",
    "                    Patches[var] = np.concatenate((Patches[var], Dataset[var]), axis = 0)\n",
    "        return(Patches)        \n",
    "    #\n",
    "    def __call__(self):\n",
    "        Patches = self.concatenate_patches()\n",
    "        for v, var in enumerate(Patches):\n",
    "            if v == 0:\n",
    "                Number_of_samples = np.shape(Patches[var][:,:,:])[0]\n",
    "        return(Patches, Number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f3cf42-17ce-4edf-a3c7-cc8f80f145f9",
   "metadata": {},
   "source": [
    "# Shuffle and clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b43697e-bd41-4076-b577-1241ce678c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class shuffle_and_clean_dataset():\n",
    "    def __init__(self, Patches, target_var_cleaning):\n",
    "        self.Patches = Patches\n",
    "        self.target_var_cleaning = target_var_cleaning\n",
    "    #\n",
    "    def clean_data(self):\n",
    "        Clean_dataset = {}\n",
    "        idx_nan = np.isnan(np.nanmean(self.Patches[self.target_var_cleaning][:,:,:], axis = (1,2)))\n",
    "        Number_of_valid_samples = np.sum(idx_nan == False)\n",
    "        for var in self.Patches:\n",
    "            Clean_dataset[var] = self.Patches[var][idx_nan == False,:,:]\n",
    "        return(Clean_dataset, Number_of_valid_samples)\n",
    "    #\n",
    "    def shuffle_patches(self, Dataset, Number_of_valid_samples):\n",
    "        Shuffled_dataset = {}\n",
    "        list_IDs_shuffled = random.sample(range(0, Number_of_valid_samples), Number_of_valid_samples)\n",
    "        for var in Dataset:\n",
    "            Shuffled_dataset[var] = Dataset[var][list_IDs_shuffled,:,:]\n",
    "        return(Shuffled_dataset)\n",
    "    #\n",
    "    def __call__(self):\n",
    "        Clean_dataset, Number_of_valid_samples = self.clean_data()\n",
    "        Shuffled_dataset = self.shuffle_patches(Clean_dataset, Number_of_valid_samples)\n",
    "        return(Shuffled_dataset, Number_of_valid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d6a05-29d7-49f7-b97d-a59efcb94cd6",
   "metadata": {},
   "source": [
    "# Write netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57378db2-c0d3-4d3c-aceb-d4659c9c71ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_netCDF(Patches, Number_of_samples, paths, patch_size):\n",
    "    output_file = paths[\"output\"] + \"Patches.nc\"\n",
    "    output_netcdf = netCDF4.Dataset(output_file, \"w\", format = \"NETCDF4\")\n",
    "    #\n",
    "    ID_patch = output_netcdf.createDimension(\"ID_patch\", Number_of_samples)\n",
    "    x = output_netcdf.createDimension(\"x\", patch_size)\n",
    "    y = output_netcdf.createDimension(\"y\", patch_size)\n",
    "    #\n",
    "    Outputs = vars()\n",
    "    for var in Patches:\n",
    "        Outputs[var] = output_netcdf.createVariable(var, \"d\", (\"ID_patch\", \"y\", \"x\"))\n",
    "        Outputs[var][:,:,:] = Patches[var]\n",
    "    #\n",
    "    output_netcdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0920ef",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f89cb16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing time:  16.49068331718445\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "Patches, Number_of_samples = create_patch_file(date_min, date_max, paths)()\n",
    "print(\"Concatenate patches done, Number of samples: \", Number_of_samples)\n",
    "Shuffled_dataset, Number_of_valid_samples = shuffle_and_clean_dataset(Patches, target_var_cleaning)()\n",
    "print(\"Shuffle patches done, Number of samples: \", Number_of_valid_samples)\n",
    "write_netCDF(Shuffled_dataset, Number_of_valid_samples, paths, patch_size)\n",
    "#\n",
    "tf = time.time()\n",
    "print(\"Computing time: \", tf - t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondaTF",
   "language": "python",
   "name": "mycondatf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
